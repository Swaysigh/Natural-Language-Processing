{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8312857",
   "metadata": {},
   "source": [
    "Find the word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bd4976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\assen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\assen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\assen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86f506e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Despite the rigorous planning and multiple contingency measures put in place by the committee, unforeseen complications—ranging from delayed shipments and miscommunication to an unexpected labor strike—significantly hindered the project's progress, prompting stakeholders to reconsider their timeline and allocate additional resources.\"\n",
    "Tokens = word_tokenize(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2b3825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in Tokens if word.isalpha()]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49b1627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b62d70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1479c73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies:\n",
      "'despite': 1\n",
      "'rigorous': 1\n",
      "'planning': 1\n",
      "'multiple': 1\n",
      "'contingency': 1\n",
      "'measure': 1\n",
      "'put': 1\n",
      "'place': 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Frequencies:\")\n",
    "for word, count in words_count.most_common(8):\n",
    "    print(f\"'{word}': {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
